"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Exploration des donn\xe9es","href":"/nlp_project/docs/intro","docId":"intro"},{"type":"link","label":"Nettoyage des donn\xe9es","href":"/nlp_project/docs/nettoyage","docId":"nettoyage"},{"type":"link","label":"Bag of word and TF IDF","href":"/nlp_project/docs/bagofword","docId":"bagofword"},{"type":"link","label":"Logistic Regression","href":"/nlp_project/docs/logestic_reg","docId":"logestic_reg"},{"type":"link","label":"Random forest","href":"/nlp_project/docs/random_forest","docId":"random_forest"},{"type":"link","label":"SVM","href":"/nlp_project/docs/svm","docId":"svm"},{"type":"link","label":"Word2Vec","href":"/nlp_project/docs/w_to_vec","docId":"w_to_vec"},{"type":"link","label":"LDA","href":"/nlp_project/docs/lda","docId":"lda"},{"type":"link","label":"BERT","href":"/nlp_project/docs/bert","docId":"bert"}]},"docs":{"bagofword":{"id":"bagofword","title":"Bag of word and TF IDF","description":"Bag of word","sidebar":"tutorialSidebar"},"bert":{"id":"bert","title":"BERT","description":"BERT (Bidirectional Encoder Representations from Transformers) est un mod\xe8le de traitement du langage naturel d\xe9velopp\xe9 par Google en 2018. C\'est un mod\xe8le de pr\xe9traitement de texte qui peut \xeatre utilis\xe9 comme base pour diff\xe9rentes t\xe2ches de traitement du langage naturel, telles que la reconnaissance de la parole, la traduction automatique et la compr\xe9hension du langage naturel.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Exploration des donn\xe9es","description":"Explorons les donn\xe9es","sidebar":"tutorialSidebar"},"lda":{"id":"lda","title":"LDA","description":"8 LDA","sidebar":"tutorialSidebar"},"logestic_reg":{"id":"logestic_reg","title":"Logistic Regression","description":"La r\xe9gression logistique est un mod\xe8le de classification utilis\xe9 en apprentissage automatique pour pr\xe9dire une variable cible qui prend deux valeurs possibles (par exemple, oui/non, vrai/faux). Elle est souvent utilis\xe9e pour pr\xe9dire l\'appartenance d\'un \xe9chantillon \xe0 l\'une ou l\'autre des classes.","sidebar":"tutorialSidebar"},"nettoyage":{"id":"nettoyage","title":"Nettoyage des donn\xe9es","description":"Avant de commencer tout traitement, on doit absolument nettoyer nos donn\xe9es, pour r\xe9ussir \xe0 faire ceci on applique deux proc\xe9dure \xe0 nos news la lemmitization_** et le stemming_","sidebar":"tutorialSidebar"},"random_forest":{"id":"random_forest","title":"Random forest","description":"Random Forest est un mod\xe8le d\'apprentissage automatique utilis\xe9 pour la classification et la r\xe9gression. Il s\'agit d\'un ensemble de mod\xe8les de d\xe9cision bas\xe9s sur des arbres de d\xe9cision, dans lesquels chaque arbre est entra\xeen\xe9 sur une sous-partie al\xe9atoire des donn\xe9es d\'entra\xeenement et sur un sous-ensemble al\xe9atoire de caract\xe9ristiques.","sidebar":"tutorialSidebar"},"svm":{"id":"svm","title":"SVM","description":"Le SVM (Support Vector Machine) est un mod\xe8le d\'apprentissage automatique utilis\xe9 pour la classification et la r\xe9gression. Il consiste \xe0 trouver un hyperplan dans un espace \xe0 n dimensions qui s\xe9pare le mieux possible les diff\xe9rentes classes de donn\xe9es.","sidebar":"tutorialSidebar"},"w_to_vec":{"id":"w_to_vec","title":"Word2Vec","description":"7 Word2Vec","sidebar":"tutorialSidebar"}}}')}}]);